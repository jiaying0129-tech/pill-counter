import streamlit as st
import cv2
import numpy as np

# --- 1. ä»‹é¢è¨­å®š ---
st.set_page_config(page_title="é€šç”¨æ™ºæ…§æ•¸è—¥ä¸¸", layout="centered")
st.markdown("""
    <style>
    .main { background-color: #0E1117; color: white; }
    h1 { color: #FFD700; text-align: center; }
    .stButton>button { 
        width: 100%; border-radius: 12px; height: 60px; 
        font-size: 20px; font-weight: bold;
        background-color: #FFD700; color: black; border: none;
    }
    </style>
""", unsafe_allow_html=True)

st.title("ğŸ’Š é€šç”¨æ™ºæ…§æ•¸è—¥ä¸¸")
st.info("ğŸ¤– æ­¤ç‰ˆæœ¬ä½¿ç”¨ã€Œç¾¤é«”åˆ†ææ¼”ç®—æ³•ã€ã€‚ä¸é™é¡è‰²å½¢ç‹€ï¼Œæœƒè‡ªå‹•éæ¿¾æ‰ä¸åˆç¾¤çš„é›œè¨Šï¼ˆå¦‚ç“¶è“‹åå…‰ï¼‰ã€‚")

# --- 2. åƒæ•¸ (åƒ…ä¿ç•™è¦–é‡å¾®èª¿) ---
with st.expander("ğŸ“ å¦‚æœæŠ“åˆ°èƒŒæ™¯ï¼Œè«‹èª¿æ•´è¦–é‡ç¯„åœ"):
    scope_size = st.slider("è¦–é‡ç¯„åœ (0.5 = åªçœ‹ç•«é¢ä¸­é–“ 50%)", 0.3, 0.9, 0.6)

# --- 3. æ ¸å¿ƒé‚è¼¯ï¼šé€šç”¨é©æ‡‰æ€§æ¼”ç®—æ³• ---
def smart_analysis(img_buffer, scope):
    # 1. è®€å–
    file_bytes = np.asarray(bytearray(img_buffer.read()), dtype=np.uint8)
    img = cv2.imdecode(file_bytes, 1)
    h, w = img.shape[:2]
    
    # 2. è¦–é‡è£åˆ‡ (èšç„¦ä¸­å¿ƒ)
    # æˆ‘å€‘ä¸åªæ˜¯å¡—é»‘ï¼Œè€Œæ˜¯ç›´æ¥åˆ‡å‡ºä¾†é‹ç®—ï¼Œæ¸›å°‘é‹ç®—é‡
    crop_h, crop_w = int(h*scope), int(w*scope)
    start_y, start_x = (h - crop_h)//2, (w - crop_w)//2
    cropped = img[start_y:start_y+crop_h, start_x:start_x+crop_w]
    
    # 3. è½‰ç°éš + å¼·åŠ›æ¨¡ç³Š (å»é™¤ç´‹è·¯èˆ‡åˆ»ç—•)
    gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)
    # ä½¿ç”¨é›™é‚Šæ¿¾æ³¢ (Bilateral Filter) ä¿ç•™é‚Šç·£ä½†æ¨¡ç³Šè¡¨é¢ (å»é™¤ R å­—)
    blurred = cv2.bilateralFilter(gray, 9, 75, 75)
    # å†åŠ é«˜æ–¯æ¨¡ç³Šç¢ºä¿å…‰æ»‘
    blurred = cv2.GaussianBlur(blurred, (11, 11), 0)
    
    # 4. é©æ‡‰æ€§é–¾å€¼ (Adaptive Threshold) - é€šç”¨é—œéµï¼
    # ä¸ç®¡è—¥ä¸¸æ˜¯ä»€éº¼é¡è‰²ï¼Œåªè¦è·ŸèƒŒæ™¯æœ‰äº®åº¦å·®ï¼Œé€™å€‹æ–¹æ³•éƒ½èƒ½æŠ“åˆ°
    binary = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                 cv2.THRESH_BINARY_INV, 25, 3)
    
    # 5. å½¢æ…‹å­¸æ“ä½œ (ä¿®è£œèˆ‡æ–·é–‹)
    kernel = np.ones((3,3), np.uint8)
    # é–‹é‹ç®—ï¼šå»é™¤å°ç™½é»é›œè¨Š
    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=2)
    # é–‰é‹ç®—ï¼šæŠŠè—¥ä¸¸å…§éƒ¨çš„ç©ºæ´å¡«æ»¿
    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=3)
    
    # 6. è·é›¢è®Šæ› + åˆ†æ°´å¶º (åˆ†é›¢æ²¾é»)
    dist_transform = cv2.distanceTransform(binary, cv2.DIST_L2, 5)
    # é€™è£¡ç”¨è¼ƒä½çš„é–¾å€¼ (0.4) ä¾†ç¢ºä¿ä¸åŒå½¢ç‹€çš„è—¥ä¸¸éƒ½èƒ½æ‰¾åˆ°æ ¸å¿ƒ
    _, peaks = cv2.threshold(dist_transform, 0.4 * dist_transform.max(), 255, 0)
    peaks = np.uint8(peaks)
    
    cnts, _ = cv2.findContours(peaks, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # === 7. æ™ºæ…§éæ¿¾ç³»çµ± (Smart Filter) ===
    # é€™æ˜¯è¸¢æ‰ç¬¬ 5 é»(ç“¶è“‹åå…‰)çš„é—œéµ
    
    final_candidates = []
    
    # 7a. æ”¶é›†æ‰€æœ‰å€™é¸é»çš„è³‡è¨Š
    candidates_data = []
    for c in cnts:
        area = cv2.contourArea(c)
        if area < 10: continue # éæ¿¾æ¥µå°å™ªé»
        
        M = cv2.moments(c)
        if M["m00"] != 0:
            cX = int(M["m10"] / M["m00"])
            cY = int(M["m01"] / M["m00"])
            candidates_data.append({'cnt': c, 'area': area, 'center': (cX, cY)})
    
    # 7b. è¨ˆç®—ç¾¤é«”ä¸­ä½æ•¸ (å¤§å®¶é€šå¸¸å¤šå¤§ï¼Ÿ)
    if candidates_data:
        areas = [d['area'] for d in candidates_data]
        median_area = np.median(areas)
        
        # è¨ˆç®—ç¾¤é«”é‡å¿ƒ (å¤§å®¶èšåœ¨å“ªè£¡ï¼Ÿ)
        centers = np.array([d['center'] for d in candidates_data])
        group_center = np.mean(centers, axis=0)
        
        for item in candidates_data:
            # è¦å‰‡ 1: å¤§å°éæ¿¾
            # å¦‚æœé€™å€‹é»æ¯”ã€Œå¹³å‡å¤§å°ã€å°å¤ªå¤š (ä¾‹å¦‚å°æ–¼ 1/5)ï¼Œé‚£å°±æ˜¯é›œè¨Š (ç“¶è“‹åå…‰é€šå¸¸æ¯”è¼ƒå°)
            if item['area'] < median_area * 0.2:
                continue
            
            # è¦å‰‡ 2: è·é›¢éæ¿¾
            # è¨ˆç®—é€™å€‹é»é›¢ã€Œå¤§å®¶ã€æœ‰å¤šé 
            dist_from_group = np.linalg.norm(np.array(item['center']) - group_center)
            
            # å¦‚æœé€™å€‹é»é›¢ç¾¤é«”çš„ä¸­å¿ƒå¤ªé  (å¤§æ–¼ç•«é¢å¯¬åº¦çš„ 40%)ï¼Œåˆ¤å®šç‚ºé‚Šç·£é›œè¨Š
            if dist_from_group > crop_w * 0.4:
                continue
                
            final_candidates.append(item)
            
    # 8. ç¹ªåœ–
    count = len(final_candidates)
    output_img = cropped.copy()
    
    for i, item in enumerate(final_candidates):
        cX, cY = item['center']
        cv2.circle(output_img, (cX, cY), 10, (0, 0, 255), -1) # ç´…é»
        cv2.circle(output_img, (cX, cY), 25, (0, 255, 0), 2) # ç¶ åœˆ
        cv2.putText(output_img, str(i+1), (cX-10, cY-10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)

    return count, output_img, binary

# --- 4. åŸ·è¡Œå€ ---
img_file = st.camera_input("ğŸ“¸ è«‹æ‹ç…§")

if img_file is not None:
    count, result_img, debug_bin = smart_analysis(img_file, scope_size)
    
    st.success("æ™ºæ…§åˆ†æå®Œæˆï¼")
    st.markdown(f"<div style='text-align: center; font-size: 80px; font-weight: bold; color: #FFD700;'>{count} é¡†</div>", unsafe_allow_html=True)
    
    st.image(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB), caption="åµæ¸¬çµæœ (å·²éæ¿¾é›¢ç¾¤é›œè¨Š)", use_container_width=True)
    
    with st.expander("ğŸ§  AI æ˜¯å¦‚ä½•æ€è€ƒçš„ï¼Ÿ (é™¤éŒ¯)"):
        st.write("1. **é©æ‡‰æ€§è¦–è¦º**ï¼šä¸åˆ†é¡è‰²ï¼ŒåªæŠ“çµæ§‹ã€‚")
        st.image(debug_bin, caption="é›»è…¦çœ‹åˆ°çš„çµæ§‹åœ–", use_container_width=True)
        st.write("2. **ç¾¤é«”éæ¿¾**ï¼šç¨‹å¼è¨ˆç®—äº†æ‰€æœ‰é»çš„å¹³å‡å¤§å°å’Œä½ç½®ï¼ŒæŠŠè§’è½é‚£å€‹é•·å¾—ä¸ä¸€æ¨£ã€é›¢å¤§å®¶å¤ªé çš„é›œè¨Šè¸¢æ‰äº†ã€‚")
