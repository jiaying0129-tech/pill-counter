import streamlit as st
import cv2
import numpy as np

# --- 1. ä»‹é¢è¨­å®š ---
st.set_page_config(page_title="AI èšå…‰ç‡ˆæ•¸è—¥ä¸¸", layout="centered")
st.markdown("""
    <style>
    .main { background-color: #0E1117; color: white; }
    h1 { color: #00FF00; text-align: center; }
    .stButton>button { 
        width: 100%; border-radius: 50px; height: 70px; 
        font-size: 24px; font-weight: bold;
        background-color: #00CC00; color: white;
    }
    </style>
""", unsafe_allow_html=True)

st.title("ğŸ’Š AI èšå…‰ç‡ˆæ•¸è—¥ä¸¸")
st.warning("ğŸ¯ è«‹å°‡è—¥ä¸¸æ”¾åœ¨ç•«é¢**æ­£ä¸­é–“**ã€‚ç¨‹å¼æœƒè‡ªå‹•æŠŠå‘¨åœå¡—é»‘ï¼Œç„¡è¦–èƒŒæ™¯ã€‚")

# --- 2. æ ¸å¿ƒé‚è¼¯ï¼šèšå…‰ç‡ˆæ¼”ç®—æ³• ---
def spotlight_analysis(img_buffer):
    # è®€å–
    file_bytes = np.asarray(bytearray(img_buffer.read()), dtype=np.uint8)
    img = cv2.imdecode(file_bytes, 1)
    h, w = img.shape[:2]
    
    # === ç¬¬ä¸€æ­¥ï¼šå»ºç«‹å¼·åŠ›èšå…‰ç‡ˆ (Spotlight Mask) ===
    # é€™æ˜¯è§£æ±ºä½ å•é¡Œçš„é—œéµï¼
    # æˆ‘å€‘å»ºç«‹ä¸€å€‹å…¨é»‘çš„é®ç½©ï¼Œåªåœ¨æ­£ä¸­é–“æŒ–ä¸€å€‹æ´
    mask = np.zeros((h, w), dtype=np.uint8)
    center_x, center_y = w // 2, h // 2
    
    # è¨­å®šåŠå¾‘ç‚ºçŸ­é‚Šçš„ 35% (éå¸¸ç©æ¥µçš„éæ¿¾ï¼Œå¼·åˆ¶åªçœ‹ä¸­é–“)
    radius = int(min(h, w) * 0.35)
    cv2.circle(mask, (center_x, center_y), radius, 255, -1)
    
    # å¥—ç”¨é®ç½©ï¼šé®ç½©å¤–çš„æ±è¥¿å…¨éƒ¨è®Šå…¨é»‘ (R=0, G=0, B=0)
    img_spotlight = cv2.bitwise_and(img, img, mask=mask)
    
    # === ç¬¬äºŒæ­¥ï¼šç¶ è‰²é€šé“åˆ†æ (Green Channel) ===
    # å°æ–¼ç²‰ç´…è—¥ä¸¸èˆ‡æœ¨ç´‹èƒŒæ™¯ï¼Œç¶ è‰²é€šé“é€šå¸¸æ˜¯æœ€ä¹¾æ·¨çš„
    b, g, r = cv2.split(img_spotlight)
    gray = g
    
    # === ç¬¬ä¸‰æ­¥ï¼šå°æ¯”åº¦æ¥µé™å¢å¼· ===
    # è®“è—¥ä¸¸äº®åˆ°çˆ†ï¼ŒèƒŒæ™¯æš—ä¸‹å»
    clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8,8))
    enhanced = clahe.apply(gray)
    
    # === ç¬¬å››æ­¥ï¼šé–¾å€¼è™•ç† (Threshold) ===
    # é€™è£¡æˆ‘å€‘ç”¨ä¸€å€‹æŠ€å·§ï¼šåªå°ã€Œæœ‰äº®å…‰çš„åœ°æ–¹ã€åš Otsu
    # é€™æ¨£é»‘è‰²çš„èƒŒæ™¯å°±ä¸æœƒå¹²æ“¾è¨ˆç®—
    # å…ˆåšé«˜æ–¯æ¨¡ç³Šå»å™ª
    blurred = cv2.GaussianBlur(enhanced, (15, 15), 0)
    _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    
    # å†æ¬¡å¼·åˆ¶å¥—ç”¨åœ“å½¢é®ç½© (ç¢ºä¿é‚Šç·£æ²’æœ‰æ®˜ç•™ç™½é‚Š)
    binary = cv2.bitwise_and(binary, binary, mask=mask)
    
    # === ç¬¬äº”æ­¥ï¼šåˆ†é›¢é»åœ¨ä¸€èµ·çš„è—¥ä¸¸ ===
    # è·é›¢è®Šæ›
    dist_transform = cv2.distanceTransform(binary, cv2.DIST_L2, 5)
    
    # æ‰¾å³°å€¼ (Peaks)
    # é€™è£¡è¨­å®š 0.5 (50% äº®åº¦)ï¼Œé€™æ˜¯ä¸€å€‹å¾ˆå®‰å…¨çš„æ•¸å€¼ï¼Œèƒ½åˆ†é–‹å¤§éƒ¨åˆ†åœ“å½¢è—¥ä¸¸
    _, peaks = cv2.threshold(dist_transform, 0.5 * dist_transform.max(), 255, 0)
    peaks = np.uint8(peaks)
    
    # === ç¬¬å…­æ­¥ï¼šè¨ˆæ•¸èˆ‡é›™é‡éæ¿¾ ===
    cnts, _ = cv2.findContours(peaks, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    count = 0
    output_img = img.copy() # ç•«åœ¨åŸåœ–ä¸Š
    
    # ç•«å‡ºèšå…‰ç‡ˆç¯„åœçµ¦ä½¿ç”¨è€…çœ‹
    cv2.circle(output_img, (center_x, center_y), radius, (0, 255, 255), 2)
    
    for c in cnts:
        area = cv2.contourArea(c)
        if area < 10: continue # éæ¿¾æ¥µå°å™ªé»
        
        # è¨ˆç®—ä¸­å¿ƒé»
        M = cv2.moments(c)
        if M["m00"] != 0:
            cX = int(M["m10"] / M["m00"])
            cY = int(M["m01"] / M["m00"])
            
            # ã€çµ‚æ¥µéæ¿¾ã€‘ï¼šå¦‚æœåµæ¸¬é»é›¢åœ“å¿ƒå¤ªé ï¼Œä¸€å®šæ˜¯èª¤åˆ¤ (æ¯”å¦‚è“‹å­é‚Šç·£)
            dist_from_center = np.sqrt((cX - center_x)**2 + (cY - center_y)**2)
            if dist_from_center > radius * 0.9:
                continue
            
            count += 1
            
            # ç•«æ¨™è¨˜
            cv2.circle(output_img, (cX, cY), 8, (0, 0, 255), -1) # ç´…é»
            cv2.circle(output_img, (cX, cY), 20, (0, 255, 0), 2) # ç¶ åœˆ
            cv2.putText(output_img, str(count), (cX-10, cY-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)

    return count, output_img, binary, img_spotlight

# --- 3. åŸ·è¡Œå€ ---
img_file = st.camera_input("ğŸ“¸ è«‹é»æ­¤æ‹ç…§")

if img_file is not None:
    count, result_img, debug_bin, debug_spot = spotlight_analysis(img_file)
    
    st.success("åˆ†æå®Œæˆï¼")
    st.markdown(f"<div style='text-align: center; font-size: 80px; font-weight: bold; color: #00FF00;'>{count} é¡†</div>", unsafe_allow_html=True)
    
    st.image(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB), caption="AI åµæ¸¬çµæœ (é»ƒåœˆå…§ç‚ºåµæ¸¬ç¯„åœ)", use_container_width=True)
    
    with st.expander("ğŸ‘€ ç‚ºä»€éº¼é€™æ¬¡é›œè¨Šä¸è¦‹äº†ï¼Ÿ"):
        col1, col2 = st.columns(2)
        with col1:
            st.image(debug_spot, caption="1. èšå…‰ç‡ˆæ•ˆæœ", use_container_width=True)
            st.write("ç¨‹å¼å¼·åˆ¶æŠŠå‘¨åœå¡—é»‘ï¼Œæœ¨ç´‹ç›´æ¥æ¶ˆå¤±ã€‚")
        with col2:
            st.image(debug_bin, caption="2. æœ€çµ‚åˆ¤è®€", use_container_width=True)
            st.write("ä¹¾æ·¨çš„é»‘ç™½å½±åƒï¼Œåªå‰©ä¸­é–“çš„è—¥ä¸¸ã€‚")
