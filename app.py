import streamlit as st
import cv2
import numpy as np
from PIL import Image

# --- 1. é é¢è¨­å®š ---
st.set_page_config(page_title="AI è—¥ä¸¸è¨ˆæ•¸å™¨ (é«˜å°æ¯”ç‰ˆ)", layout="centered")

st.markdown("""
    <style>
    .main { background-color: #f0f2f6; }
    h1 { color: #d63384; text-align: center; }
    .stButton>button { width: 100%; border-radius: 20px; }
    </style>
""", unsafe_allow_html=True)

st.title("ğŸ’Š è—¥ä¸¸è¨ˆæ•¸å™¨ - é«˜å°æ¯”ç‰ˆ")
st.info("ğŸ’¡ é‡å°ã€Œç²‰è‰²è—¥ä¸¸+æ·±è‰²è“‹å­ã€å„ªåŒ–ã€‚è«‹ä½¿ç”¨ä¸‹æ–¹çš„ã€Œè£åˆ‡ã€åŠŸèƒ½å»é™¤æœ¨ç´‹èƒŒæ™¯ã€‚")

# --- 2. å´é‚Šæ¬„ï¼šåƒæ•¸èª¿æ•´ ---
with st.expander("âš™ï¸ èª¿æ•´åƒæ•¸ (ç®—ä¸æº–è«‹é»æˆ‘)", expanded=True):
    st.write("### 1. ç¯„åœè¨­å®š")
    crop_size = st.slider("è£åˆ‡é‚Šç·£ (å»é™¤èƒŒæ™¯)", 0, 200, 50, help="æ•¸å€¼è¶Šå¤§ï¼Œåˆ‡æ‰çš„é‚Šç·£è¶Šå¤š")
    
    st.write("### 2. å½±åƒå¢å¼·")
    use_green_channel = st.checkbox("é–‹å•Ÿã€Œç¶ è‰²æ¿¾é¡ã€ (ç²‰ç´…è—¥ä¸¸æ¨è–¦)", value=True, help="ç²‰ç´…è‰²åœ¨ç¶ è‰²æ¿¾é¡ä¸‹å°æ¯”æœ€å¼·")
    contrast_boost = st.slider("å°æ¯”åº¦å¢å¼· (CLAHE)", 0.0, 10.0, 3.0)
    
    st.write("### 3. åˆ†é›¢è¨­å®š")
    block_size = st.slider("å€åŸŸåµæ¸¬å¤§å° (å¥‡æ•¸)", 3, 51, 15, step=2, help="è¶Šå°è¶Šèƒ½æŠ“åˆ°ç´°ç¯€ï¼Œä½†ä¹Ÿå®¹æ˜“æŠ“åˆ°é›œè¨Š")
    separation_force = st.slider("åˆ†é›¢å¼·åº¦", 0.0, 1.0, 0.4)
    min_area = st.slider("æœ€å°é¢ç© (éæ¿¾é›œè¨Š)", 10, 500, 100)

# --- 3. æ ¸å¿ƒè™•ç†é‚è¼¯ ---
def process_image(img_buffer, crop_val, use_green, contrast, blk_size, sep_force, min_area_val):
    # è®€å–åœ–ç‰‡
    file_bytes = np.asarray(bytearray(img_buffer.read()), dtype=np.uint8)
    img = cv2.imdecode(file_bytes, 1)
    
    # 1. è£åˆ‡å½±åƒ (å»é™¤æœ¨ç´‹èƒŒæ™¯)
    h, w = img.shape[:2]
    if crop_val > 0:
        img = img[crop_val:h-crop_val, crop_val:w-crop_val]
    
    # 2. é¡è‰²é€šé“é¸æ“‡ (é—œéµæ­¥é©Ÿ)
    if use_green:
        # ç²‰ç´…è‰² = é«˜ç´… + é«˜è— + ä¸­ç¶ 
        # ç´…è‰²è“‹å­ = é«˜ç´… + ä½ç¶  + ä½è—
        # å–ç¶ è‰²é€šé“ï¼Œé€šå¸¸èƒ½è®“ç²‰ç´…è—¥ä¸¸(è¼ƒäº®)è·Ÿæ·±ç´…è“‹å­(è¼ƒæš—)åˆ†é–‹
        b, g, r = cv2.split(img)
        gray = g
    else:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # 3. å¢å¼·å°æ¯” (CLAHE)
    # é€™èƒ½è®“é™°å½±è£¡çš„è—¥ä¸¸é¡¯ç¾å‡ºä¾†
    clahe = cv2.createCLAHE(clipLimit=contrast, tileGridSize=(8,8))
    gray = clahe.apply(gray)
    
    # 4. é«˜æ–¯æ¨¡ç³Š (æ¸›å°‘å™ªé»)
    blurred = cv2.GaussianBlur(gray, (9, 9), 0)
    
    # 5. é©æ‡‰æ€§é–¾å€¼ (Adaptive Threshold)
    # è‡ªå‹•æ ¹æ“šå€åŸŸå…‰ç·šæ±ºå®šé»‘ç™½ï¼Œä¸å†ç”¨å…¨åŸŸå›ºå®šæ•¸å€¼
    thresh = cv2.adaptiveThreshold(
        blurred, 255, 
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
        cv2.THRESH_BINARY, 
        blk_size, 2
    )
    
    # 6. å½¢æ…‹å­¸æ¸…ç† (å»é™¤å°ç™½é»)
    kernel = np.ones((3,3), np.uint8)
    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)
    
    # 7. è·é›¢è®Šæ› (åˆ†é›¢é»åœ¨ä¸€èµ·çš„è—¥ä¸¸)
    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)
    _, sure_fg = cv2.threshold(dist_transform, sep_force * dist_transform.max(), 255, 0)
    sure_fg = np.uint8(sure_fg)
    
    # 8. æ‰¾è¼ªå»“
    cnts, _ = cv2.findContours(sure_fg.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    count = 0
    output_img = img.copy()
    
    for c in cnts:
        if cv2.contourArea(c) < min_area_val:
            continue
            
        count += 1
        
        # æ‰¾ä¸­å¿ƒé»
        M = cv2.moments(c)
        if M["m00"] != 0:
            cX = int(M["m10"] / M["m00"])
            cY = int(M["m01"] / M["m00"])
            
            # ç¹ªè£½çµæœ
            cv2.circle(output_img, (cX, cY), 8, (0, 0, 255), -1) 
            cv2.putText(output_img, str(count), (cX - 10, cY - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            
            x, y, w, h = cv2.boundingRect(c)
            cv2.rectangle(output_img, (x, y), (x + w, y + h), (0, 255, 0), 2)

    return count, output_img, gray, sure_fg

# --- 4. ä»‹é¢é¡¯ç¤º ---
img_file = st.camera_input("ğŸ“¸ è«‹ç›¡é‡å°‡è—¥ä¸¸æ”¾åœ¨ç•«é¢æ­£ä¸­é–“")

if img_file is not None:
    count, result_img, debug_gray, debug_fg = process_image(
        img_file, crop_size, use_green_channel, contrast_boost, block_size, separation_force, min_area
    )
    
    st.markdown(f"<h2 style='text-align: center; color: #d63384;'>å…±ç™¼ç¾ {count} é¡†</h2>", unsafe_allow_html=True)
    st.image(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB), caption="æœ€çµ‚çµæœ", use_container_width=True)
    
    # é™¤éŒ¯å€
    with st.expander("ğŸ‘€ é›»è…¦çœ‹åˆ°äº†ä»€éº¼ï¼Ÿ (é™¤éŒ¯å½±åƒ)"):
        col1, col2 = st.columns(2)
        with col1:
            st.write("1. ç¶ è‰²æ¿¾é¡+å°æ¯”å¢å¼·")
            st.write("ç¢ºèªè—¥ä¸¸åœ¨é€™è£¡æ˜¯å¦æ¯”èƒŒæ™¯äº®ï¼Ÿ")
            st.image(debug_gray, use_container_width=True)
        with col2:
            st.write("2. æœ€çµ‚è­˜åˆ¥å€åŸŸ")
            st.write("ç¢ºèªç™½é»æ˜¯å¦åˆ†é–‹ï¼Ÿ")
            st.image(debug_fg, use_container_width=True, clamp=True)
